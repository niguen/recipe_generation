{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, Dense, concatenate, Embedding, ReLU, Dropout, Bidirectional, GRU, Add, Concatenate\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "UNITS = 512\n",
    "\n",
    "BUFFER_SIZE = 120\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "max_name_features = 10000\n",
    "max_name_len = 4\n",
    "\n",
    "max_ingredient_features = 4000\n",
    "max_ingredient_len = 4\n",
    "\n",
    "max_step_features = 10000\n",
    "max_step_len = 400"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join('data', 'recipe_dataset.txt')\n",
    "# Using readlines()\n",
    "file1 = open(text_path, 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "names = []\n",
    "ingredients = []\n",
    "steps = []\n",
    "\n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    pieces = line.split('\\t')\n",
    "    names.append(pieces[0])\n",
    "    ingredients.append(pieces[1])\n",
    "    steps.append(pieces[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name count: 36652\n",
      "Ingredient count: 36652\n",
      "Step count: 36652\n"
     ]
    }
   ],
   "source": [
    "print(f'Name count: {len(names)}')\n",
    "print(f'Ingredient count: {len(ingredients)}')\n",
    "print(f'Step count: {len(steps)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensor Flow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(names)\n",
    "ingredients = np.array(ingredients)\n",
    "steps = np.array(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(names)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train = np.random.uniform(size=(len(names),)) < 0.8\n",
    "\n",
    "# train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\"names\": names[is_train], \"ingredients\": ingredients[is_train]}, steps[is_train]))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\"names\": names[~is_train], \"ingredients\": ingredients[~is_train]}, steps[~is_train]))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Text Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_vectorizer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=max_step_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_step_len)\n",
    "\n",
    "#train_raw.map(lambda context, target: context)\n",
    "step_vectorizer.adapt(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'step', 'and', 'the', 'in', 'a', 'to', 'until', 'with']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_vectorizer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=max_ingredient_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_ingredient_len)\n",
    "\n",
    "#train_raw.map(lambda context, target: context)\n",
    "\n",
    "ingredient_vectorizer.adapt(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'sugar',\n",
       " 'butter',\n",
       " 'salt',\n",
       " 'eggs',\n",
       " 'flour',\n",
       " 'vanilla',\n",
       " 'bakingpowder',\n",
       " 'milk']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_vectorizer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=max_name_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_name_len)\n",
    "\n",
    "#train_raw.map(lambda context, target: context)\n",
    "name_vectorizer.adapt(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'cake',\n",
       " 'cookies',\n",
       " 'chocolate',\n",
       " 's',\n",
       " 'pie',\n",
       " 'cream',\n",
       " 'apple',\n",
       " 'with']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(inputs, outputs):\n",
    "\n",
    "  names = inputs['names']\n",
    "  ingredients = inputs['ingredients']\n",
    "\n",
    "  name_context = name_vectorizer(names)\n",
    "  ingredient_context = ingredient_vectorizer(ingredients)\n",
    "  context = {'names': name_context, 'ingredients': ingredient_context}\n",
    "\n",
    "  target = step_vectorizer(outputs)\n",
    "  targ_in = target[:,:-1]\n",
    "  targ_out = target[:,1:]\n",
    "  return (context, targ_in), targ_out\n",
    "\n",
    "\n",
    "train_ds = train_dataset.map(process_text, tf.data.AUTOTUNE)\n",
    "test_ds = test_dataset.map(process_text, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[388 375 589 196]\n",
      "[139   3  17   5]\n",
      "\n",
      "[898  37 710  15 551 327   3 228   6 289]\n",
      "[ 37 710  15 551 327   3 228   6 289 179]\n"
     ]
    }
   ],
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "  \n",
    "  name_tok = ex_context_tok['names']\n",
    "  ingredient_tok = ex_context_tok['ingredients']\n",
    "  print(name_tok[0, :10].numpy()) \n",
    "  print(ingredient_tok[0, :10].numpy()) \n",
    "  print()\n",
    "\n",
    "  print(ex_tar_in[0, :10].numpy()) \n",
    "  print(ex_tar_out[0, :10].numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, name_processor, ingredient_processor, units):\n",
    "    super(Encoder, self).__init__()\n",
    "    \n",
    "    self.name_processor = name_processor\n",
    "    self.ingredient_processor = ingredient_processor\n",
    "\n",
    "    self.name_vocab_size = name_processor.vocabulary_size()\n",
    "    self.ingredient_vocab_size = ingredient_processor.vocabulary_size()\n",
    "    \n",
    "    self.units = units\n",
    "\n",
    "    # The embedding layer converts tokens to vectors\n",
    "    self.name_embedding = tf.keras.layers.Embedding(self.name_vocab_size, units, mask_zero=True)\n",
    "    self.ingredient_embedding = tf.keras.layers.Embedding(self.ingredient_vocab_size, units, mask_zero=True)\n",
    "\n",
    "    self.concat = Concatenate(axis=-1)\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding((self.name_vocab_size + self.ingredient_vocab_size), units, mask_zero=True)\n",
    "    #self.embedding = tf.keras.layers.Embedding(self.name_vocab_size, units, mask_zero=True)\n",
    "\n",
    "    # The RNN layer processes those vectors sequentially.\n",
    "    self.rnn = tf.keras.layers.Bidirectional(\n",
    "        merge_mode='sum',\n",
    "        layer=tf.keras.layers.GRU(units,\n",
    "                            # Return the sequence and state\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "  def call(self, x):\n",
    "\n",
    "\n",
    "    names = x['names']\n",
    "    ingredients = x['ingredients']\n",
    "\n",
    "    #shape_checker = ShapeChecker()\n",
    "    #shape_checker(x, 'batch s')\n",
    "\n",
    "    # 2. The embedding layer looks up the embedding vector for each token.\n",
    "    x1 = self.name_embedding(names)\n",
    "    print(f'Dimensions of x1: {x1.shape}')\n",
    "    x2 = self.ingredient_embedding(ingredients)\n",
    "    print(f'Dimensions of x2: {x2.shape}')\n",
    "    x = self.concat([x1, x2])\n",
    "    print(f'Dimensions of x after concat: {x.shape}')\n",
    "\n",
    "\n",
    "    #print(f'Dimensions of x after concat: {x.shape}')\n",
    "    #x = x1\n",
    "    #x = self.embedding(x)\n",
    "\n",
    "    #shape_checker(x, 'batch s units')\n",
    "    \n",
    "   \n",
    "   \n",
    "    # 3. The GRU processes the sequence of embeddings.\n",
    "    x = self.rnn(x)\n",
    "    print(f'Dimensions of x after rnn: {x.shape}')\n",
    "    #shape_checker(x, 'batch s units')\n",
    "  \n",
    "    # 4. Returns the new sequence of embeddings.\n",
    "    return x\n",
    "\n",
    "  def convert_input(self, ingredients, names):\n",
    "\n",
    "    names = self.name_processor(names)#.to_tensor()\n",
    "    print(f'Name Tokens: {names}')\n",
    "    \n",
    "    ingredients = self.ingredient_processor(ingredients)#.to_tensor()\n",
    "    print(f'Ingredients Tokens: {ingredients}')\n",
    "    x = {\"names\": names, \"ingredients\": ingredients}\n",
    "    context = self(x)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (64, 4, 256)\n",
      "Dimensions of x2: (64, 4, 256)\n",
      "Dimensions of x after concat: (64, 4, 512)\n",
      "Dimensions of x after rnn: (64, 4, 256)\n",
      "Encoder output, shape (batch, s, units): (64, 4, 256)\n"
     ]
    }
   ],
   "source": [
    "# Encode the input sequence.\n",
    "encoder = Encoder(name_vectorizer, ingredient_vectorizer, UNITS)\n",
    "ex_context = encoder(ex_context_tok)\n",
    "\n",
    "#print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens: [[ 4 18  0  0]]\n",
      "Ingredients Tokens: [[2 4 5 7]]\n",
      "Dimensions of x1: (1, 4, 256)\n",
      "Dimensions of x2: (1, 4, 256)\n",
      "Dimensions of x after concat: (1, 4, 512)\n",
      "Dimensions of x after rnn: (1, 4, 256)\n",
      "tf.Tensor(\n",
      "[[[ 0.00345971 -0.00146917 -0.00825283 ...  0.04161211  0.03363555\n",
      "    0.00550004]\n",
      "  [ 0.0049318  -0.02693354 -0.00681243 ...  0.02628828 -0.0112592\n",
      "    0.01580709]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]], shape=(1, 4, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = encoder.convert_input(['sugar, salt, eggs, vanilla'], ['chocolate brownies'])\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "  def call(self, x, context):\n",
    "    #shape_checker = ShapeChecker()\n",
    "\n",
    "    #shape_checker(x, 'batch t units')\n",
    "    #shape_checker(context, 'batch s units')\n",
    "\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    #shape_checker(x, 'batch t units')\n",
    "    #shape_checker(attn_scores, 'batch heads t s')\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "    #shape_checker(attn_scores, 'batch t s')\n",
    "    self.last_attention_weights = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context sequence, shape (batch, s, units): (64, 4, 256)\n",
      "Target sequence, shape (batch, t, units): (64, 399, 256)\n",
      "Attention result, shape (batch, t, units): (64, 399, 256)\n",
      "Attention weights, shape (batch, t, s):    (64, 399, 4)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = CrossAttention(UNITS)\n",
    "\n",
    "# Attend to the encoded tokens\n",
    "embed = tf.keras.layers.Embedding(step_vectorizer.vocabulary_size(),\n",
    "                                  output_dim=UNITS, mask_zero=True)\n",
    "ex_tar_embed = embed(ex_tar_in)\n",
    "\n",
    "result = attention_layer(ex_tar_embed, ex_context)\n",
    "\n",
    "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
    "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
    "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
    "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999994, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.0000001 , 1.        ,\n",
       "       1.        , 1.0000001 , 1.        , 0.99999994, 1.        ,\n",
       "       1.0000001 , 1.0000001 , 1.0000001 , 1.        , 1.0000001 ,\n",
       "       0.99999994, 1.        , 1.        , 1.        , 0.99999994,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.99999994, 0.99999994, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.0000001 , 1.        ,\n",
       "       1.        , 1.0000001 , 1.        , 0.99999994, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99999994,\n",
       "       1.        , 1.        , 0.99999994, 0.99999994, 0.99999994,\n",
       "       1.0000001 , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, text_processor, units):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab_size = text_processor.vocabulary_size()\n",
    "    self.word_to_id = tf.keras.layers.StringLookup(\n",
    "        vocabulary=text_processor.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]')\n",
    "    self.id_to_word = tf.keras.layers.StringLookup(\n",
    "        vocabulary=text_processor.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]',\n",
    "        invert=True)\n",
    "    self.start_token = self.word_to_id('[START]')\n",
    "    self.end_token = self.word_to_id('[END]')\n",
    "\n",
    "    self.units = units\n",
    "\n",
    "\n",
    "    # 1. The embedding layer converts token IDs to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
    "                                               units, mask_zero=True)\n",
    "\n",
    "    # 2. The RNN keeps track of what's been generated so far.\n",
    "    self.rnn = tf.keras.layers.GRU(units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    # 3. The RNN output will be the query for the attention layer.\n",
    "    self.attention = CrossAttention(units)\n",
    "\n",
    "    # 4. This fully connected layer produces the logits for each\n",
    "    # output token.\n",
    "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def call(self,\n",
    "         context, x,\n",
    "         state=None,\n",
    "         return_state=False):  \n",
    "  #shape_checker = ShapeChecker()\n",
    "  #shape_checker(x, 'batch t')\n",
    "  #shape_checker(context, 'batch s units')\n",
    "\n",
    "  # 1. Lookup the embeddings\n",
    "  x = self.embedding(x)\n",
    "  #shape_checker(x, 'batch t units')\n",
    "\n",
    "  # 2. Process the target sequence.\n",
    "  x, state = self.rnn(x, initial_state=state)\n",
    "  #shape_checker(x, 'batch t units')\n",
    "\n",
    "  # 3. Use the RNN output as the query for the attention over the context.\n",
    "  x = self.attention(x, context)\n",
    "  self.last_attention_weights = self.attention.last_attention_weights\n",
    "  #shape_checker(x, 'batch t units')\n",
    "  #shape_checker(self.last_attention_weights, 'batch t s')\n",
    "\n",
    "  x, state_2 = self.rnn(x, initial_state=state_2)\n",
    "\n",
    "  # Step 4. Generate logit predictions for the next token.\n",
    "  logits = self.output_layer(x)\n",
    "  #shape_checker(logits, 'batch t target_vocab_size')\n",
    "\n",
    "  if return_state:\n",
    "    return logits, state\n",
    "  else:\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(step_vectorizer, UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output shape: (batch, s, units) (64, 4, 256)\n",
      "input target tokens shape: (batch, t) (64, 399)\n",
      "logits shape shape: (batch, target_vocabulary_size) (64, 399, 10000)\n"
     ]
    }
   ],
   "source": [
    "logits = decoder(ex_context, ex_tar_in)\n",
    "\n",
    "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
    "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_initial_state(self, context):\n",
    "  batch_size = tf.shape(context)[0]\n",
    "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "  embedded = self.embedding(start_tokens)\n",
    "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def tokens_to_text(self, tokens):\n",
    "  words = self.id_to_word(tokens)\n",
    "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
    "  logits, state = self(\n",
    "    context, next_token,\n",
    "    state = state,\n",
    "    return_state=True) \n",
    "\n",
    "  if temperature == 0.0:\n",
    "    next_token = tf.argmax(logits, axis=-1)\n",
    "  else:\n",
    "    logits = logits[:, -1, :]/temperature\n",
    "    next_token = tf.random.categorical(logits, num_samples=1)\n",
    "\n",
    "  # If a sequence produces an `end_token`, set it `done`\n",
    "  done = done | (next_token == self.end_token)\n",
    "  # Once a sequence is done it only produces 0-padding.\n",
    "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
    "\n",
    "  return next_token, done, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'mme requests oates yucky bitesize farenheit cant checked orange 7in',\n",
       "       b'pecans pepper smotth icecubes 1518 lodge 4x4 4s souffl dripping',\n",
       "       b'unpeeled always pyramids repeating meltetd losing softer firstly srape ahead'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the loop variables.\n",
    "next_token, done, state = decoder.get_initial_state(ex_context)\n",
    "tokens = []\n",
    "\n",
    "for n in range(10):\n",
    "  # Run one step.\n",
    "  next_token, done, state = decoder.get_next_token(\n",
    "      ex_context, next_token, done, state, temperature=1.0)\n",
    "  # Add the token to the output.\n",
    "  tokens.append(next_token)\n",
    "\n",
    "# Stack all the tokens together.\n",
    "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
    "\n",
    "# Convert the tokens back to a a string\n",
    "result = decoder.tokens_to_text(tokens)\n",
    "result[:3].numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.keras.Model):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, units,\n",
    "               name_vectorizer,\n",
    "               ingredient_vectorizer,\n",
    "               step_vectorizer):\n",
    "    super().__init__()\n",
    "    # Build the encoder and decoder\n",
    "    encoder = Encoder(name_vectorizer, ingredient_vectorizer, units)\n",
    "    decoder = Decoder(step_vectorizer, units)\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def call(self, inputs):\n",
    "    context, x = inputs\n",
    "    context = self.encoder(context)\n",
    "    logits = self.decoder(context, x)\n",
    "\n",
    "    #TODO(b/250038731): remove this\n",
    "    try:\n",
    "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (64, 4, 256)\n",
      "Dimensions of x2: (64, 4, 256)\n",
      "Dimensions of x after concat: (64, 4, 512)\n",
      "Dimensions of x after rnn: (64, 4, 256)\n",
      "Target tokens, shape: (batch, t) (64, 399)\n",
      "logits, shape: (batch, t, target_vocabulary_size) (64, 399, 10000)\n"
     ]
    }
   ],
   "source": [
    "model = Translator(UNITS, name_vectorizer, ingredient_vectorizer, step_vectorizer)\n",
    "\n",
    "logits = model((ex_context_tok, ex_tar_in))\n",
    "\n",
    "#print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
    "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_acc(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "\n",
    "    match = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=masked_loss, \n",
    "              metrics=[masked_acc, masked_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expected_loss': 9.2103405, 'expected_acc': 0.0001}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 1.0 * step_vectorizer.vocabulary_size()\n",
    "\n",
    "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
    " \"expected_acc\": 1/vocab_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "20/20 [==============================] - 90s 4s/step - loss: 9.2155 - masked_acc: 8.9531e-05 - masked_loss: 9.2155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 9.21550178527832,\n",
       " 'masked_acc': 8.953099313657731e-05,\n",
       " 'masked_loss': 9.21550178527832}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds, steps=20, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      " 15/100 [===>..........................] - ETA: 9:06 - loss: 7.3850 - masked_acc: 0.0798 - masked_loss: 7.3850"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     train_ds\u001b[39m.\u001b[39;49mrepeat(), \n\u001b[0;32m      3\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m     steps_per_epoch \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     validation_data\u001b[39m=\u001b[39;49mtest_ds,\n\u001b[0;32m      6\u001b[0m     validation_steps \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      8\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(patience\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)])\n",
      "File \u001b[1;32mc:\\HRW\\NLP\\nlp-recipe-generation\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\HRW\\NLP\\nlp-recipe-generation\\venv\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\HRW\\NLP\\nlp-recipe-generation\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\HRW\\NLP\\nlp-recipe-generation\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\HRW\\NLP\\nlp-recipe-generation\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\HRW\\NLP\\nlp-recipe-generation\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\HRW\\NLP\\nlp-recipe-generation\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\HRW\\NLP\\nlp-recipe-generation\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\HRW\\NLP\\nlp-recipe-generation\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds.repeat(), \n",
    "    epochs=10,\n",
    "    steps_per_epoch = 100,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps = 20,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rezepte generieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Translator.add_method\n",
    "def translate(self, ingredients, names, *, max_length=400, temperature=0.0):\n",
    "  context = self.encoder.convert_input(ingredients, names)\n",
    "  batch_size = tf.shape(names)[0]\n",
    "  \n",
    "  # Setup the loop inputs\n",
    "  tokens = []\n",
    "  attention_weights = []\n",
    "  next_token, done, state = self.decoder.get_initial_state(context)\n",
    "\n",
    "  for _ in range(max_length):\n",
    "    # Generate the next token\n",
    "    next_token, done, state = self.decoder.get_next_token(\n",
    "        context, next_token, done,  state, temperature)\n",
    "\n",
    "    # Collect the generated tokens\n",
    "    tokens.append(next_token)\n",
    "    attention_weights.append(self.decoder.last_attention_weights)\n",
    "\n",
    "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "      break\n",
    "\n",
    "  # Stack the lists of tokens and attention weights.\n",
    "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
    "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
    "\n",
    "  result = self.decoder.tokens_to_text(tokens)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens: [[3 0 0 0]]\n",
      "Ingredients Tokens: [[3 4 5 6]]\n",
      "Dimensions of x1: (1, 4, 256)\n",
      "Dimensions of x2: (1, 4, 256)\n",
      "Dimensions of x after concat: (1, 4, 512)\n",
      "Dimensions of x after rnn: (1, 4, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cake mix cake mix eggs and oil in a large bowl step beat in eggs one at a time beating well after each addition step add flour mixture and beat until combined step pour into prepared pan step bake at 350 degrees for 25 minutes or until cake tests done'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.translate(['sugar, salt, eggs, vanilla'], ['cake'])\n",
    "result[0].numpy().decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens: Tensor(\"text_vectorization_2/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 4), dtype=int64)\n",
      "Ingredients Tokens: Tensor(\"text_vectorization_1/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 4), dtype=int64)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.embedding.Embedding object at 0x0000024D06A7B1F0>, because it is not built.\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, embedding_5_layer_call_fn, embedding_5_layer_call_and_return_conditional_losses, embedding_6_layer_call_fn, embedding_6_layer_call_and_return_conditional_losses while saving (showing 5 of 37). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator\\assets\n"
     ]
    }
   ],
   "source": [
    "class Export(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None]), tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
    "  def translate(self, ingredients, names):\n",
    "    return self.model.translate(ingredients, names)\n",
    "\n",
    "export = Export(model)\n",
    "\n",
    "tf.saved_model.save(export, 'translator', signatures={'serving_default': export.translate})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3b175500661b34c9810fb06f07c17ae229594eb81df44f5824523195c835e54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
