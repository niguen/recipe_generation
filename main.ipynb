{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, Dense, concatenate, Embedding, ReLU, Dropout, Bidirectional, GRU, Add, Concatenate\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "UNITS = 256\n",
    "\n",
    "BUFFER_SIZE = 120\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "max_name_features = 10000\n",
    "max_name_len = 4\n",
    "\n",
    "max_ingredient_features = 4000\n",
    "max_ingredient_len = 4\n",
    "\n",
    "max_step_features = 10000\n",
    "max_step_len = 400"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join('data', 'choc_recipes.txt')\n",
    "# Using readlines()\n",
    "file1 = open(text_path, 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "names = []\n",
    "ingredients = []\n",
    "steps = []\n",
    "\n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    pieces = line.split('\\t')\n",
    "    names.append(pieces[0])\n",
    "    ingredients.append(pieces[1])\n",
    "    steps.append(pieces[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_list_list = []\n",
    "for i_string in ingredients:\n",
    "    i = i_string.replace(', ', '*')\n",
    "    i = i.replace(' ', '_')\n",
    "    i = i.replace('*', ', ')\n",
    "\n",
    "    ingredients_list_list.append(i)\n",
    "\n",
    "ingredients = ingredients_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name count: 29512\n",
      "Ingredient count: 29512\n",
      "Step count: 29512\n"
     ]
    }
   ],
   "source": [
    "print(f'Name count: {len(names)}')\n",
    "print(f'Ingredient count: {len(ingredients)}')\n",
    "print(f'Step count: {len(steps)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensor Flow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(names)\n",
    "ingredients = np.array(ingredients)\n",
    "steps = np.array(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(names)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train = np.random.uniform(size=(len(names),)) < 0.8\n",
    "\n",
    "# train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\"names\": names[is_train], \"ingredients\": ingredients[is_train]}, steps[is_train]))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\"names\": names[~is_train], \"ingredients\": ingredients[~is_train]}, steps[~is_train]))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Text Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_vectorizer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=max_step_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_step_len)\n",
    "\n",
    "#train_raw.map(lambda context, target: context)\n",
    "step_vectorizer.adapt(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'step', 'and', 'the', 'in', 'a', 'to', 'until', 'with']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_vectorizer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=max_ingredient_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_ingredient_len)\n",
    "\n",
    "#train_raw.map(lambda context, target: context)\n",
    "\n",
    "ingredient_vectorizer.adapt(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'sugar',\n",
       " 'butter',\n",
       " 'salt',\n",
       " 'eggs',\n",
       " 'flour',\n",
       " 'vanilla',\n",
       " 'bakingpowder',\n",
       " 'bakingsoda']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredient_vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_vectorizer = tf.keras.layers.TextVectorization(\n",
    " max_tokens=max_name_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_name_len)\n",
    "\n",
    "#train_raw.map(lambda context, target: context)\n",
    "name_vectorizer.adapt(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'cake',\n",
       " 'chocolate',\n",
       " 'cookies',\n",
       " 's',\n",
       " 'pie',\n",
       " 'cream',\n",
       " 'with',\n",
       " 'butter']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_vectorizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(inputs, outputs):\n",
    "\n",
    "  names = inputs['names']\n",
    "  ingredients = inputs['ingredients']\n",
    "\n",
    "  name_context = name_vectorizer(names)\n",
    "  ingredient_context = ingredient_vectorizer(ingredients)\n",
    "  context = {'names': name_context, 'ingredients': ingredient_context}\n",
    "\n",
    "  target = step_vectorizer(outputs)\n",
    "  targ_in = target[:,:-1]\n",
    "  targ_out = target[:,1:]\n",
    "  return (context, targ_in), targ_out\n",
    "\n",
    "\n",
    "train_ds = train_dataset.map(process_text, tf.data.AUTOTUNE)\n",
    "test_ds = test_dataset.map(process_text, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[410 417 788 203]\n",
      "[177   3  17   5]\n",
      "\n",
      "[848  38 806  13 565 306   3 203   6 299]\n",
      "[ 38 806  13 565 306   3 203   6 299 181]\n"
     ]
    }
   ],
   "source": [
    "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
    "  \n",
    "  name_tok = ex_context_tok['names']\n",
    "  ingredient_tok = ex_context_tok['ingredients']\n",
    "  print(name_tok[0, :10].numpy()) \n",
    "  print(ingredient_tok[0, :10].numpy()) \n",
    "  print()\n",
    "\n",
    "  print(ex_tar_in[0, :10].numpy()) \n",
    "  print(ex_tar_out[0, :10].numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, name_processor, ingredient_processor, units):\n",
    "    super(Encoder, self).__init__()\n",
    "    \n",
    "    self.name_processor = name_processor\n",
    "    self.ingredient_processor = ingredient_processor\n",
    "\n",
    "    self.name_vocab_size = name_processor.vocabulary_size()\n",
    "    self.ingredient_vocab_size = ingredient_processor.vocabulary_size()\n",
    "    \n",
    "    self.units = units\n",
    "\n",
    "    # The embedding layer converts tokens to vectors\n",
    "    self.name_embedding = tf.keras.layers.Embedding(self.name_vocab_size, units, mask_zero=True)\n",
    "    self.ingredient_embedding = tf.keras.layers.Embedding(self.ingredient_vocab_size, units, mask_zero=True)\n",
    "\n",
    "    self.concat = Concatenate(axis=-1)\n",
    "\n",
    "    self.embedding = tf.keras.layers.Embedding((self.name_vocab_size + self.ingredient_vocab_size), units, mask_zero=True)\n",
    "    #self.embedding = tf.keras.layers.Embedding(self.name_vocab_size, units, mask_zero=True)\n",
    "\n",
    "    # The RNN layer processes those vectors sequentially.\n",
    "    self.rnn = tf.keras.layers.Bidirectional(\n",
    "        merge_mode='sum',\n",
    "        layer=tf.keras.layers.GRU(units,\n",
    "                            # Return the sequence and state\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "  def call(self, x):\n",
    "\n",
    "\n",
    "    names = x['names']\n",
    "    ingredients = x['ingredients']\n",
    "\n",
    "    #shape_checker = ShapeChecker()\n",
    "    #shape_checker(x, 'batch s')\n",
    "\n",
    "    # 2. The embedding layer looks up the embedding vector for each token.\n",
    "    x1 = self.name_embedding(names)\n",
    "    print(f'Dimensions of x1: {x1.shape}')\n",
    "    x2 = self.ingredient_embedding(ingredients)\n",
    "    print(f'Dimensions of x2: {x2.shape}')\n",
    "    x = self.concat([x1, x2])\n",
    "    print(f'Dimensions of x after concat: {x.shape}')\n",
    "\n",
    "\n",
    "    #print(f'Dimensions of x after concat: {x.shape}')\n",
    "    #x = x1\n",
    "    #x = self.embedding(x)\n",
    "\n",
    "    #shape_checker(x, 'batch s units')\n",
    "    \n",
    "   \n",
    "   \n",
    "    # 3. The GRU processes the sequence of embeddings.\n",
    "    x = self.rnn(x)\n",
    "    print(f'Dimensions of x after rnn: {x.shape}')\n",
    "    #shape_checker(x, 'batch s units')\n",
    "  \n",
    "    # 4. Returns the new sequence of embeddings.\n",
    "    return x\n",
    "\n",
    "  def convert_input(self, ingredients, names):\n",
    "\n",
    "    names = self.name_processor(names)#.to_tensor()\n",
    "    print(f'Name Tokens: {names}')\n",
    "    \n",
    "    ingredients = self.ingredient_processor(ingredients)#.to_tensor()\n",
    "    print(f'Ingredients Tokens: {ingredients}')\n",
    "    x = {\"names\": names, \"ingredients\": ingredients}\n",
    "    context = self(x)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (64, 4, 256)\n",
      "Dimensions of x2: (64, 4, 256)\n",
      "Dimensions of x after concat: (64, 4, 512)\n",
      "Dimensions of x after rnn: (64, 4, 256)\n",
      "Encoder output, shape (batch, s, units): (64, 4, 256)\n"
     ]
    }
   ],
   "source": [
    "# Encode the input sequence.\n",
    "encoder = Encoder(name_vectorizer, ingredient_vectorizer, UNITS)\n",
    "ex_context = encoder(ex_context_tok)\n",
    "\n",
    "#print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
    "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens: [[ 3 17  0  0]]\n",
      "Ingredients Tokens: [[2 4 5 7]]\n",
      "Dimensions of x1: (1, 4, 256)\n",
      "Dimensions of x2: (1, 4, 256)\n",
      "Dimensions of x after concat: (1, 4, 512)\n",
      "Dimensions of x after rnn: (1, 4, 256)\n",
      "tf.Tensor(\n",
      "[[[ 0.00926014  0.00822703  0.01127694 ...  0.03982471  0.00012917\n",
      "   -0.01180315]\n",
      "  [ 0.01781792  0.0376748  -0.00790119 ...  0.00802552 -0.02521122\n",
      "   -0.00383423]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]], shape=(1, 4, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = encoder.convert_input(['sugar, salt, eggs, vanilla'], ['chocolate brownies'])\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "  def call(self, x, context):\n",
    "    #shape_checker = ShapeChecker()\n",
    "\n",
    "    #shape_checker(x, 'batch t units')\n",
    "    #shape_checker(context, 'batch s units')\n",
    "\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    #shape_checker(x, 'batch t units')\n",
    "    #shape_checker(attn_scores, 'batch heads t s')\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "    #shape_checker(attn_scores, 'batch t s')\n",
    "    self.last_attention_weights = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context sequence, shape (batch, s, units): (64, 4, 256)\n",
      "Target sequence, shape (batch, t, units): (64, 399, 256)\n",
      "Attention result, shape (batch, t, units): (64, 399, 256)\n",
      "Attention weights, shape (batch, t, s):    (64, 399, 4)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = CrossAttention(UNITS)\n",
    "\n",
    "# Attend to the encoded tokens\n",
    "embed = tf.keras.layers.Embedding(step_vectorizer.vocabulary_size(),\n",
    "                                  output_dim=UNITS, mask_zero=True)\n",
    "ex_tar_embed = embed(ex_tar_in)\n",
    "\n",
    "result = attention_layer(ex_tar_embed, ex_context)\n",
    "\n",
    "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
    "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
    "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
    "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 0.99999994,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.99999994, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99999994,\n",
       "       1.        , 1.0000001 , 1.0000001 , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.0000001 , 1.0000001 , 1.        ,\n",
       "       1.0000001 , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.0000001 , 0.99999994, 1.        ,\n",
       "       1.        , 1.        , 1.0000001 , 1.        , 0.99999994,\n",
       "       1.        , 1.        , 0.99999994, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.99999994, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        ], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, text_processor, units):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab_size = text_processor.vocabulary_size()\n",
    "    self.word_to_id = tf.keras.layers.StringLookup(\n",
    "        vocabulary=text_processor.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]')\n",
    "    self.id_to_word = tf.keras.layers.StringLookup(\n",
    "        vocabulary=text_processor.get_vocabulary(),\n",
    "        mask_token='', oov_token='[UNK]',\n",
    "        invert=True)\n",
    "    self.start_token = self.word_to_id('[START]')\n",
    "    self.end_token = self.word_to_id('[END]')\n",
    "\n",
    "    self.units = units\n",
    "\n",
    "\n",
    "    # 1. The embedding layer converts token IDs to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
    "                                               units, mask_zero=True)\n",
    "\n",
    "    # 2. The RNN keeps track of what's been generated so far.\n",
    "    self.rnn = tf.keras.layers.GRU(units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    # 3. The RNN output will be the query for the attention layer.\n",
    "    self.attention = CrossAttention(units)\n",
    "\n",
    "    # 4. This fully connected layer produces the logits for each\n",
    "    # output token.\n",
    "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def call(self,\n",
    "         context, x,\n",
    "         state=None,\n",
    "         return_state=False):  \n",
    "  #shape_checker = ShapeChecker()\n",
    "  #shape_checker(x, 'batch t')\n",
    "  #shape_checker(context, 'batch s units')\n",
    "\n",
    "  # 1. Lookup the embeddings\n",
    "  x = self.embedding(x)\n",
    "  #shape_checker(x, 'batch t units')\n",
    "\n",
    "  # 2. Process the target sequence.\n",
    "  x, state = self.rnn(x, initial_state=state)\n",
    "  #shape_checker(x, 'batch t units')\n",
    "\n",
    "  # 3. Use the RNN output as the query for the attention over the context.\n",
    "  x = self.attention(x, context)\n",
    "  self.last_attention_weights = self.attention.last_attention_weights\n",
    "  #shape_checker(x, 'batch t units')\n",
    "  #shape_checker(self.last_attention_weights, 'batch t s')\n",
    "\n",
    "  # Step 4. Generate logit predictions for the next token.\n",
    "  logits = self.output_layer(x)\n",
    "  #shape_checker(logits, 'batch t target_vocab_size')\n",
    "\n",
    "  if return_state:\n",
    "    return logits, state\n",
    "  else:\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(step_vectorizer, UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output shape: (batch, s, units) (64, 4, 256)\n",
      "input target tokens shape: (batch, t) (64, 399)\n",
      "logits shape shape: (batch, target_vocabulary_size) (64, 399, 10000)\n"
     ]
    }
   ],
   "source": [
    "logits = decoder(ex_context, ex_tar_in)\n",
    "\n",
    "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
    "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_initial_state(self, context):\n",
    "  batch_size = tf.shape(context)[0]\n",
    "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "  embedded = self.embedding(start_tokens)\n",
    "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def tokens_to_text(self, tokens):\n",
    "  words = self.id_to_word(tokens)\n",
    "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Decoder.add_method\n",
    "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
    "  logits, state = self(\n",
    "    context, next_token,\n",
    "    state = state,\n",
    "    return_state=True) \n",
    "\n",
    "  if temperature == 0.0:\n",
    "    next_token = tf.argmax(logits, axis=-1)\n",
    "  else:\n",
    "    logits = logits[:, -1, :]/temperature\n",
    "    next_token = tf.random.categorical(logits, num_samples=1)\n",
    "\n",
    "  # If a sequence produces an `end_token`, set it `done`\n",
    "  done = done | (next_token == self.end_token)\n",
    "  # Once a sequence is done it only produces 0-padding.\n",
    "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
    "\n",
    "  return next_token, done, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'golded guessing 230f section modifications according moisture 5862 sale fave',\n",
       "       b'milkvinegar veggies skinny soured 246 slipping rasberry roller stirring thyme',\n",
       "       b'loosebottomed tablespoonfuls refrigerating shaken trangles bundts teaspoonsful necessary ketchup pool'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the loop variables.\n",
    "next_token, done, state = decoder.get_initial_state(ex_context)\n",
    "tokens = []\n",
    "\n",
    "for n in range(10):\n",
    "  # Run one step.\n",
    "  next_token, done, state = decoder.get_next_token(\n",
    "      ex_context, next_token, done, state, temperature=1.0)\n",
    "  # Add the token to the output.\n",
    "  tokens.append(next_token)\n",
    "\n",
    "# Stack all the tokens together.\n",
    "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
    "\n",
    "# Convert the tokens back to a a string\n",
    "result = decoder.tokens_to_text(tokens)\n",
    "result[:3].numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.keras.Model):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, units,\n",
    "               name_vectorizer,\n",
    "               ingredient_vectorizer,\n",
    "               step_vectorizer):\n",
    "    super().__init__()\n",
    "    # Build the encoder and decoder\n",
    "    encoder = Encoder(name_vectorizer, ingredient_vectorizer, units)\n",
    "    decoder = Decoder(step_vectorizer, units)\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def call(self, inputs):\n",
    "    context, x = inputs\n",
    "    context = self.encoder(context)\n",
    "    logits = self.decoder(context, x)\n",
    "\n",
    "    #TODO(b/250038731): remove this\n",
    "    try:\n",
    "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (64, 4, 256)\n",
      "Dimensions of x2: (64, 4, 256)\n",
      "Dimensions of x after concat: (64, 4, 512)\n",
      "Dimensions of x after rnn: (64, 4, 256)\n",
      "Target tokens, shape: (batch, t) (64, 399)\n",
      "logits, shape: (batch, t, target_vocabulary_size) (64, 399, 10000)\n"
     ]
    }
   ],
   "source": [
    "model = Translator(UNITS, name_vectorizer, ingredient_vectorizer, step_vectorizer)\n",
    "\n",
    "logits = model((ex_context_tok, ex_tar_in))\n",
    "\n",
    "#print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
    "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
    "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_acc(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "\n",
    "    match = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=masked_loss, \n",
    "              metrics=[masked_acc, masked_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expected_loss': 9.2103405, 'expected_acc': 0.0001}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 1.0 * step_vectorizer.vocabulary_size()\n",
    "\n",
    "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
    " \"expected_acc\": 1/vocab_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "20/20 [==============================] - 69s 3s/step - loss: 9.2131 - masked_acc: 7.7998e-05 - masked_loss: 9.2131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 9.21313190460205,\n",
       " 'masked_acc': 7.79976398916915e-05,\n",
       " 'masked_loss': 9.21313190460205}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds, steps=20, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 531s 5s/step - loss: 2.1757 - masked_acc: 0.4836 - masked_loss: 2.1757 - val_loss: 2.5843 - val_masked_acc: 0.4384 - val_masked_loss: 2.5843\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 543s 5s/step - loss: 2.2425 - masked_acc: 0.4749 - masked_loss: 2.2425 - val_loss: 2.5756 - val_masked_acc: 0.4383 - val_masked_loss: 2.5756\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 543s 5s/step - loss: 2.2660 - masked_acc: 0.4706 - masked_loss: 2.2660 - val_loss: 2.5594 - val_masked_acc: 0.4416 - val_masked_loss: 2.5594\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 544s 5s/step - loss: 2.2641 - masked_acc: 0.4711 - masked_loss: 2.2641 - val_loss: 2.5508 - val_masked_acc: 0.4430 - val_masked_loss: 2.5508\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 542s 5s/step - loss: 2.1109 - masked_acc: 0.4951 - masked_loss: 2.1109 - val_loss: 2.5687 - val_masked_acc: 0.4424 - val_masked_loss: 2.5687\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 540s 5s/step - loss: 2.1870 - masked_acc: 0.4827 - masked_loss: 2.1870 - val_loss: 2.5718 - val_masked_acc: 0.4386 - val_masked_loss: 2.5718\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 540s 5s/step - loss: 2.1958 - masked_acc: 0.4810 - masked_loss: 2.1958 - val_loss: 2.5664 - val_masked_acc: 0.4415 - val_masked_loss: 2.5664\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds.repeat(), \n",
    "    epochs=20,\n",
    "    steps_per_epoch = 100,\n",
    "    validation_data=test_ds,\n",
    "    validation_steps = 20,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rezepte generieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Translator.add_method\n",
    "def translate(self, ingredients, names, *, max_length=50, temperature=0.0):\n",
    "  context = self.encoder.convert_input(ingredients, names)\n",
    "  batch_size = tf.shape(names)[0]\n",
    "  \n",
    "  # Setup the loop inputs\n",
    "  tokens = []\n",
    "  attention_weights = []\n",
    "  next_token, done, state = self.decoder.get_initial_state(context)\n",
    "\n",
    "  for _ in range(max_length):\n",
    "    # Generate the next token\n",
    "    next_token, done, state = self.decoder.get_next_token(\n",
    "        context, next_token, done,  state, temperature)\n",
    "\n",
    "    # Collect the generated tokens\n",
    "    tokens.append(next_token)\n",
    "    attention_weights.append(self.decoder.last_attention_weights)\n",
    "\n",
    "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "      break\n",
    "\n",
    "  # Stack the lists of tokens and attention weights.\n",
    "  tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
    "  self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
    "\n",
    "  result = self.decoder.tokens_to_text(tokens)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens: [[2 0 0 0]]\n",
      "Ingredients Tokens: [[2 4 5 7]]\n",
      "Dimensions of x1: (1, 4, 256)\n",
      "Dimensions of x2: (1, 4, 256)\n",
      "Dimensions of x after concat: (1, 4, 512)\n",
      "Dimensions of x after rnn: (1, 4, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cake mix sugar and butter in a large bowl step beat in eggs and vanilla step combine flour and baking powder step add to creamed mixture alternately with milk step pour into greased and floured tube pan step bake at 350 for 1 hour step cool step in a small'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.translate(['sugar, salt, eggs, vanilla'], ['cake'])\n",
    "result[0].numpy().decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens: Tensor(\"text_vectorization_5/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 4), dtype=int64)\n",
      "Ingredients Tokens: Tensor(\"text_vectorization_4/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 4), dtype=int64)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.embedding.Embedding object at 0x000001EA4663C160>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.embedding.Embedding object at 0x000001EA4663C160>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n",
      "Dimensions of x1: (None, 4, 256)\n",
      "Dimensions of x2: (None, 4, 256)\n",
      "Dimensions of x after concat: (None, 4, 512)\n",
      "Dimensions of x after rnn: (None, 4, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, embedding_14_layer_call_fn, embedding_14_layer_call_and_return_conditional_losses, embedding_15_layer_call_fn, embedding_15_layer_call_and_return_conditional_losses while saving (showing 5 of 37). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator\\assets\n"
     ]
    }
   ],
   "source": [
    "class Export(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None]), tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
    "  def translate(self, ingredients, names):\n",
    "    return self.model.translate(ingredients, names)\n",
    "\n",
    "export = Export(model)\n",
    "\n",
    "tf.saved_model.save(export, 'translator', signatures={'serving_default': export.translate})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d7ae0224bd89de4449d250d925cca589efca98a76d1c6b139cf4cb688201e3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
